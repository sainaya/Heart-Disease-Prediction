{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dySKaJqSms_B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk \n",
    "import re \n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "# importing neural network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential ,Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, Embedding, LSTM, Input, Bidirectional, Conv1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "FckdvP2Rm-eE",
    "outputId": "475224a7-f6f4-4973-a76f-a68703273bd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   condition  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "NyQczULbnneu",
    "outputId": "a2eb0de1-a600-466c-d7c7-d7259ef41c51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
       "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
       "       'diaBP', 'BMI', 'heartRate', 'glucose', 'condition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "melbtQUBnp1Z"
   },
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_maBIz6cv-Fr"
   },
   "outputs": [],
   "source": [
    "num_class = len(np.unique(data.condition.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2oN5Zv-Rnyum"
   },
   "outputs": [],
   "source": [
    "feature_data = np.asarray(data[['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
    "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
    "       'diaBP', 'BMI', 'heartRate', 'glucose']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "ELnMZVDnod6z",
    "outputId": "3688b944-4654-4b01-8fdb-ac16d135f6de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.  ,  39.  ,   4.  , ...,  26.97,  80.  ,  77.  ],\n",
       "       [  0.  ,  46.  ,   2.  , ...,  28.73,  95.  ,  76.  ],\n",
       "       [  1.  ,  48.  ,   1.  , ...,  25.34,  75.  ,  70.  ],\n",
       "       ...,\n",
       "       [  1.  ,  50.  ,   1.  , ...,  25.97,  66.  ,  86.  ],\n",
       "       [  1.  ,  51.  ,   3.  , ...,  19.71,  65.  ,  68.  ],\n",
       "       [  0.  ,  52.  ,   2.  , ...,  21.47,  80.  , 107.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "obAMtuBbnzE1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, data['condition'], test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vt0J02oin26o"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 500\n",
    "tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "RI3-fKlPou1f",
    "outputId": "88c9beaa-40f0-4742-d8d8-112291e714dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  27,  75,  70],\n",
       "       [  0,   0,   0, ...,  25,  75,  83],\n",
       "       [  0,   0,   0, ...,  35,  73,  75],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  28,  48,  76],\n",
       "       [  0,   0,   0, ...,  27,  67, 104],\n",
       "       [  0,   0,   0, ...,  30,  60,  69]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BJMivK2craL5",
    "outputId": "34287964-a73e-4acb-8ae7-0b1bee564ab9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3290, 500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "icLbWzX5o4nf",
    "outputId": "6a7640e5-eae0-4542-d665-5665d0402032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,  20,  80,  76],\n",
       "       [  0,   0,   0, ...,  20,  67,  83],\n",
       "       [  0,   0,   0, ...,  19,  70, 111],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  28,  70,  78],\n",
       "       [  0,   0,   0, ...,  21,  75,  73],\n",
       "       [  0,   0,   0, ...,  39,  85,  90]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_LENGTH)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "0rDhMF9TpmUT",
    "outputId": "c5a8d454-f97f-456b-828e-0977179c4741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes=num_class)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "JOrh_fqrsfhh",
    "outputId": "8c0ac48f-6865-4ebb-c3a0-97d30721dc72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3290, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "k_gbeoLDpo5b",
    "outputId": "0455e346-fb6f-42ea-f379-ed9c8647653f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pivQBUzqn6Th"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lQ80gI2lykKD",
    "outputId": "69dadb88-2a0b-4752-f651-ffb00bc59066"
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "iZQ5IBUHzjJi",
    "outputId": "592550d3-432d-45c6-f197-a2e60cbb63a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        ...,\n",
       "        [ 27],\n",
       "        [ 75],\n",
       "        [ 70]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        ...,\n",
       "        [ 25],\n",
       "        [ 75],\n",
       "        [ 83]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        ...,\n",
       "        [ 35],\n",
       "        [ 73],\n",
       "        [ 75]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        ...,\n",
       "        [ 28],\n",
       "        [ 48],\n",
       "        [ 76]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        ...,\n",
       "        [ 27],\n",
       "        [ 67],\n",
       "        [104]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        ...,\n",
       "        [ 30],\n",
       "        [ 60],\n",
       "        [ 69]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape((3290, 500, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 970
    },
    "id": "FO5FsHT2n-Yj",
    "outputId": "bc8f6958-21c7-4814-bbd5-6bce232cbcf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 1)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                16896     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 19,538\n",
      "Trainable params: 19,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 1.2767 - acc: 0.6869\n",
      "Epoch 00001: val_acc improved from -inf to 0.87538, saving model to model3.hdf5\n",
      "47/47 [==============================] - 7s 152ms/step - loss: 1.2767 - acc: 0.6869 - val_loss: 0.4112 - val_acc: 0.8754\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.5241 - acc: 0.7680\n",
      "Epoch 00002: val_acc did not improve from 0.87538\n",
      "47/47 [==============================] - 8s 160ms/step - loss: 0.5241 - acc: 0.7680 - val_loss: 0.3681 - val_acc: 0.8754\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4514 - acc: 0.8294\n",
      "Epoch 00003: val_acc improved from 0.87538 to 0.87842, saving model to model3.hdf5\n",
      "47/47 [==============================] - 8s 164ms/step - loss: 0.4514 - acc: 0.8294 - val_loss: 0.3691 - val_acc: 0.8784\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4308 - acc: 0.8369\n",
      "Epoch 00004: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 186ms/step - loss: 0.4308 - acc: 0.8369 - val_loss: 0.3630 - val_acc: 0.8784\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4164 - acc: 0.8386\n",
      "Epoch 00005: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 187ms/step - loss: 0.4164 - acc: 0.8386 - val_loss: 0.3605 - val_acc: 0.8784\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4170 - acc: 0.8392\n",
      "Epoch 00006: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 185ms/step - loss: 0.4170 - acc: 0.8392 - val_loss: 0.3610 - val_acc: 0.8754\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4083 - acc: 0.8409\n",
      "Epoch 00007: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 190ms/step - loss: 0.4083 - acc: 0.8409 - val_loss: 0.3749 - val_acc: 0.8784\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4064 - acc: 0.8436\n",
      "Epoch 00008: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 183ms/step - loss: 0.4064 - acc: 0.8436 - val_loss: 0.3994 - val_acc: 0.8602\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4063 - acc: 0.8450\n",
      "Epoch 00009: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 182ms/step - loss: 0.4063 - acc: 0.8450 - val_loss: 0.3584 - val_acc: 0.8754\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4036 - acc: 0.8443\n",
      "Epoch 00010: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 191ms/step - loss: 0.4036 - acc: 0.8443 - val_loss: 0.3586 - val_acc: 0.8754\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4112 - acc: 0.8403\n",
      "Epoch 00011: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 9s 184ms/step - loss: 0.4112 - acc: 0.8403 - val_loss: 0.3629 - val_acc: 0.8754\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4052 - acc: 0.8416\n",
      "Epoch 00012: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 178ms/step - loss: 0.4052 - acc: 0.8416 - val_loss: 0.3769 - val_acc: 0.8723\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4009 - acc: 0.8450\n",
      "Epoch 00013: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 180ms/step - loss: 0.4009 - acc: 0.8450 - val_loss: 0.4091 - val_acc: 0.8511\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4036 - acc: 0.8450\n",
      "Epoch 00014: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 178ms/step - loss: 0.4036 - acc: 0.8450 - val_loss: 0.3624 - val_acc: 0.8723\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4031 - acc: 0.8494\n",
      "Epoch 00015: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 175ms/step - loss: 0.4031 - acc: 0.8494 - val_loss: 0.3596 - val_acc: 0.8754\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3992 - acc: 0.8467\n",
      "Epoch 00016: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 178ms/step - loss: 0.3992 - acc: 0.8467 - val_loss: 0.3631 - val_acc: 0.8754\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4019 - acc: 0.8484\n",
      "Epoch 00017: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 179ms/step - loss: 0.4019 - acc: 0.8484 - val_loss: 0.3589 - val_acc: 0.8754\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3917 - acc: 0.8490\n",
      "Epoch 00018: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 180ms/step - loss: 0.3917 - acc: 0.8490 - val_loss: 0.3576 - val_acc: 0.8784\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3990 - acc: 0.8484\n",
      "Epoch 00019: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 177ms/step - loss: 0.3990 - acc: 0.8484 - val_loss: 0.3625 - val_acc: 0.8754\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3916 - acc: 0.8467\n",
      "Epoch 00020: val_acc did not improve from 0.87842\n",
      "47/47 [==============================] - 8s 179ms/step - loss: 0.3916 - acc: 0.8467 - val_loss: 0.3735 - val_acc: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e2f2aab80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_inputs = Input(shape=(MAX_LENGTH,1))\n",
    "# embedding_layer = Embedding(vocab_size,\n",
    "#                             128,\n",
    "#                             input_length=MAX_LENGTH, trainable=False)(sequence_inputs) \n",
    "\n",
    "\n",
    "x = LSTM(64, activation='relu')(sequence_inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs=[sequence_inputs], outputs=predictions)\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, validation_split=0.1, epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
